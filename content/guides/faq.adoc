= Frequently Asked Questions
Alex Miller
2015-01-01
:type: guides
:toc: macro
:icons: font

ifdef::env-github,env-browser[:outfilesuffix: .adoc]

toc::[]

These questions and answers are adapted from mailing lists and other Clojure community forums.

== Reader and Syntax

[[why_keywords]]
**What's the advantage of representing text tokens as keywords (instead of as strings)?**

Keywords are cached and interned. This means that a keyword is reused (reducing memory) everywhere in your program and that checks for equality really become checks for identity (which are fast). Additionally, keywords are invokable to look themselves up in a map and thus this enables the common pattern of extracting a particular field from a collection of maps possible.

[[reader_macros]]
**Why does Clojure not have user-extensible reader macros?**

The reader takes text (Clojure source) and returns Clojure data, which is subsequently compiled and evaluated. Reader macros tell the Clojure reader how to read something that is not a typical s-expression (examples are things like quoting `'` and anonymous functions `#()`). Reader macros can be used to define entirely new syntaxes read by the reader (for example: JSON, XML, or other formats) - this is a more powerful syntactic capability than regular macros (which come into play later at compile time). 

However, unlike Lisp, Clojure does not allow the user to extend this set of reader macros. This avoids the possibility of creating code that another user cannot read (because they do not have the proper reader macros). Clojure gives back some of the power of reader macros with tagged literals, allowing you to create generically readable _data_, that is still extensible.

[[underscore]]
**What does an _ mean in a let binding or parameter?**

_ has no special meaning in Clojure as a symbol. However, it is a convention to use _ (or a leading _) to denote a binding that will not be used in the expression.

[source,clojure]
----
(defn get-x [point]
  (let [[x _] point]   ;; y-value of point is unused, so mark it with _
    x))
----

[[anon_vector]]
**Why doesn't the anonymous function `#([%1])` work to construct a vector?**

`++#()++` always expands to include parens around the expression you give it, thus in this case it yields `(fn [x] ([x]))` which fails when the vector is invoked. Instead, use the vector function `++#(vector %)++` or just `vector`, which is the function being described.

== Collections, Sequences, and Transducers

[[conj]]
**Why does `conj` add to the front of a list and the back of a vector?**

Most Clojure data structure operations, including `conj` (conjoin), are designed to give the user a performance expectation. With `conj`, the expectation is that insertion should happen at the place where this operation is efficient. Lists (as linked lists) can make a constant time insertion only at the front. Vectors (indexed) are designed to expand at the back. As the user, you should consider this when you choose which data structure to use. In Clojure, vectors are used with much greater frequency.

[[seqs_vs_colls]]
**I keep forgetting that after calling sequence functions on vectors/sets, the return value no longer is no longer has vector or set semantics.**

Generally you should divide the Clojure core functions into these two categories:

- Data structure functions - take a data structure and return a modified versions of that data structure (conj, disj, assoc, dissoc, etc). These functions always take the data structure _first_.
- Sequence functions - take a "seqable" and return a seqable. [Generally we try to avoid committing to the return values actually being an instance of ISeq - this allows for performance optimizations in some cases.] Examples are map, filter, remove, etc. All of these functions take the seqable _last_.

It sounds like you are using the latter but expecting the semantics of the former (which is a common issue for new Clojurists!). If you want to apply sequence functions but have more control over the output data structure, there are a number of ways to do that.

. Use data-structure equivalents like mapv or filterv, etc - this is a very limited set that lets you perform these ops but return a data structure rather than a seqable. `(mapv inc (filterv odd? [1 2 3]))`
. Pour the results of your sequence transformations back into a data structure with into: `(into [] (map inc (filter odd? [1 2 3])))`
. Use transducers (likely with `into`) - this has much the same effect as #2, but combinations of transformations can be applied more efficiently without creating any sequences - only the final result is built: `(into [] (comp (filter odd?) (map inc)) [1 2 3])`. As you work with larger sequences or more transformations, this makes a significant difference in performance.

Note that all of these are eager transformations - they produce the output vector when you invoke them. The original sequence version `(map inc (filter odd? [1 2 3]))` is lazy and will only produce values as needed (with chunking under the hood for greater performance). Neither of these is right or wrong, but they are both useful in different circumstances.

[[transducers_vs_seqs]]
**What are good use cases for transducers?**

When performing a series of transformations, sequences will create an intermediate (cached) sequence between each transformation. Transducers create a single compound transformation that is executed in one eager pass over the input. These are different models, which are both useful.

Performance benefits of transducers:

- Source collection iteration - when used on reducible inputs (collections and other things), avoid creating an unnecessary input collection sequence - helps memory and time.
- Intermediate sequences and cached values - as the transformation happens in a single pass, you remove all intermediate sequence and cached value creation - again, helps memory and time. The combination of the the prior item and this one will start to win big as the size of the input collection or number of transformations goes up (but for small numbers of either, chunked sequences can be surprisingly fast and will compete).

Design / usage benefits of transducers:

- Transformation composition - some use cases will have a cleaner design if they separate transformation composition from transformation application. Transducers support this.
- Eagerness - transducers are great for cases where eagerly processing a transformation (and potentially encountering any errors) is more important than laziness
- Resource control - because you have more control over when the input collection is traversed, you also know when processing is complete. It's thus easier to release or clean up input resources because you know when that happens.

Performance benefits of sequences:

- Laziness - if you will only need some of the outputs (for example a user is deciding how many to use), then lazy sequences can often be more efficient in deferring processing. In particular, sequences can be lazy with intermediate results, but transducers use a pull model that will eagerly produce all intermediate values.
- Infinite streams - because transducers are typically eagerly consumed, they don't match well with infinite streams of values

Design benefits of sequences:

- Consumer control - returning a seq from an API lets you combine input + transformation into something that gives the consumer control. Transducers don't work as well for this (but will work better for cases where input and transformation are separated).

== State and Concurrency

[[concurrency_features]]
**What are the trade-offs between reducers, core.async, and futures?**

Each of these really addresses a different use case.

- Reducers are best for fine-grained data parallelism when computing a transformation over existing in-memory data (in a map or vector). Generally it's best when you have thousands of small data items to compute over and many cores to do the work. Anything described as "embarrassingly parallel".
- futures are best for pushing work onto a background thread and picking it up later (or for doing I/O waits in parallel). It's better for big chunky tasks (go fetch a bunch of data in the background).
- core.async is primarily used to organize the subsystems or internal structure of your application. It has channels (queues) to convey values from one "subprocess" (go block) to another. So you're really getting concurrency and architectural benefits in how you break up your program. The killer feature you can really only get in core.async is the ability to wait on I/O events from multiple channels for the first response on any of them (via alt/alts). Promises can also be used to convey single values between independent threads/subprocesses but they are single delivery only.
- you didn't mention pmap, but tools like pmap, java.util queues and executors, and libraries like claypoole are doing coarse-level "task" concurrency. There is some overlap with core.async here which has a very useful transducer-friendly pipeline functionality.

[[write_skew]]
**Why does the Clojure STM does not guarantee serializability but only snapshot isolation?**

If reads were included by default, then STM would be slower (as more transactions would require serializability). However, in many cases, reads do not need to be included. Thus, users can choose to accept the performance penalty when it is necessary and get faster performance when it is not.

== Namespaces

[[ns_file]]
**Do namespaces map 1-to-1 with files?**

No (although that is typical). One namespace can be split across multiple files by using `load` to load secondary files and `in-ns` in those files to retain the namespace (clojure.core is defined in this way). Also, it is possible to declare multiple namespaces in a single file (although this is very unusual).

[[ns_as_fn]]
**Do namespaces work like regular functions? Looking at the syntax, it seems ns could be returning a function that makes a namespace, and then if you just stick parens around the contents of the file, that would be a regular S expression too. Does that imply you can put more than one in a file?**

ns is a macro that does a number of things:

- creates a new internal Namespace object (if it does not yet exist)
- makes that namespace the new current namespace (*ns*)
- auto-refers all vars from clojure.core and imports all classes from java.lang
- requires/refers other namespaces and vars as specified
- (and other optional things)

ns does not return a function or anything invokable as you suggest.

While ns is typically placed at the top of a clj file, it is actually just a normal macro and can be invoked at the repl just the same. It could also be used more than once in a single file (although this would be surprising to most clj programmers and would likely not work as desired in AOT).

== Compiler

[[direct_linking_repl]]
**How does direct linking affect the REPL experience?**

Anything that has been direct linked will not see redefinitions to vars. For example, if you redefine something in clojure.core, other parts of core that use that var will not see the redefinition (however anything that you newly compile at the REPL will). In practice, this is not typically a problem.

For parts of your own app, you may wish to only enable direct linking when you build and deploy for production, rather than using it when you developing at the REPL. Or you may need to mark parts of your app with ^:redef if you want to always allow redefinition or ^:dynamic for dynamic vars.

== Java and Interop

[[inner]]
**How do you refer to a nested or inner class?**

Use a $ to separate outer from inner class name. For example: `java.util.Map$Entry` is the Entry inner class inside Map.

[[primitive_type]]
**How do you refer to the class representing a primitive?**

Primitive types can be found as the static TYPE field on the boxed class, for example: `Integer/TYPE`. 

[[varargs]]
**How do you invoke a Java method with vararg signature?**

Java treats a trailing varargs parameter as an array and it can be invoked from Clojure. Example:

`(.method object fixed-args... (into-array type variable-args...))`

Example:

[source,clojure]
----
;; asList takes an Object vararg parameter
(java.util.Arrays/asList (object-array [0 1 2]))

;; format takes one fixed parameter and a varargs
(String/format "%s %s, %s" (object-array ["March" 1 2016]))
----

== Design and Use

[[encapsulation]]
**How do you achieve encapsulation with Clojure?**

Because of its focus on immutable data, there is generally not a high value placed on data encapsulation. Because data is immutable, there is no worry about someone else modifying a value. Likewise, because Clojure data is designed to be manipulated directly, there is significant value in providing direct access to data, rather than wrapping it in APIs.

All Clojure vars are globally available so again there is not much in the way of encapsulation of functions within namespaces. However, the ability to mark vars private (either using `defn-` for functions or `def` with `^:private` for values) is a convenience for a developer to indicate which parts of an API should be considered public for use vs part of the implementation.

